# ğŸ“Š AnÃ¡lise Preditiva: Redes Neurais vs. Modelos ClÃ¡ssicos

<div align="center">

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange.svg)
![Pandas](https://img.shields.io/badge/Pandas-Data%20Analysis-green.svg)
![Scikit-learn](https://img.shields.io/badge/Scikit--learn-Machine%20Learning-red.svg)
![TensorFlow](https://img.shields.io/badge/TensorFlow-Keras-orange.svg)

**Um projeto comparativo de Machine Learning para avaliar o desempenho de Redes Neurais (Keras) contra o algoritmo Random Forest (Scikit-learn) em datasets tabulares.**

</div>

---

## ğŸ‘¥ Membros da Equipe

<div align="center">

| Nome | RM |
| :--- | :--- |
| **Wesley Sena dos Santos** | 558043 |
| **Rafael de Souza Pinto** | 555130 |
| **Samara Victoria Ferraz dos Santos** | 558719 |

</div>

---

## ğŸ“‹ Ãndice

- [ğŸ¯ VisÃ£o Geral](#-visÃ£o-geral)
- [ğŸ“ Datasets Utilizados](#-datasets-utilizados)
- [ğŸ”§ Tecnologias Utilizadas](#-tecnologias-utilizadas)
- [ğŸ“Š Metodologia](#-metodologia)
- [ğŸš€ InstalaÃ§Ã£o e Uso](#-instalaÃ§Ã£o-e-uso)
- [ğŸ“ˆ Principais Resultados](#-principais-resultados)
- [ğŸ¤– Modelos de Machine Learning](#-modelos-de-machine-learning)
- [ğŸ’¡ Insights e ConclusÃµes](#-insights-e-conclusÃµes)
- [ğŸ”® PrÃ³ximos Passos](#-prÃ³ximos-passos)
- [ğŸ“š ReferÃªncias](#-referÃªncias)

---

## ğŸ¯ VisÃ£o Geral

Este projeto realiza uma anÃ¡lise comparativa entre Redes Neurais, implementadas com a biblioteca Keras (TensorFlow), e o algoritmo Random Forest, uma tÃ©cnica de ensemble consolidada do Scikit-learn. O objetivo Ã© determinar qual abordagem oferece melhor desempenho em dois problemas distintos e clÃ¡ssicos de machine learning: uma tarefa de **classificaÃ§Ã£o multiclasse** e uma de **regressÃ£o**.

### ğŸ¯ Objetivos Principais

- **Implementar Redes Neurais**: Construir, compilar e treinar modelos de Redes Neurais para tarefas de classificaÃ§Ã£o e regressÃ£o.
- **Treinar Modelos ClÃ¡ssicos**: Utilizar o `RandomForestClassifier` e `RandomForestRegressor` como benchmarks de performance.
- **PrÃ©-processar Dados**: Aplicar tÃ©cnicas de padronizaÃ§Ã£o (`StandardScaler`) e codificaÃ§Ã£o (`OneHotEncoder`) para preparar os dados para os modelos.
- **Avaliar Performance**: Medir e comparar a acurÃ¡cia dos modelos de classificaÃ§Ã£o e o erro (MAE e RMSE) dos modelos de regressÃ£o.
- **Extrair ConclusÃµes**: Discutir os resultados e analisar por que um modelo pode ter superado o outro em cada cenÃ¡rio.

---

## ğŸ“ Datasets Utilizados

### ğŸ“Š Dataset 1: Wine Dataset (ClassificaÃ§Ã£o)

**Fonte**: RepositÃ³rio UCI (`ucimlrepo`)

#### ğŸ“‹ DescriÃ§Ã£o
Este Ã© um dataset clÃ¡ssico para tarefas de classificaÃ§Ã£o, onde o objetivo Ã© prever a qual de trÃªs diferentes produtores um vinho pertence, com base em 13 atributos quÃ­micos.

#### ğŸ“ˆ CaracterÃ­sticas dos Dados
- **Total de Registros**: 178 observaÃ§Ãµes
- **DimensÃµes**: 178 Ã— 13 variÃ¡veis de entrada (features)
- **Classes**: 3 classes de vinhos

#### ğŸ”§ VariÃ¡veis do Dataset

| VariÃ¡vel | Tipo | DescriÃ§Ã£o |
|:---|:---|:---|
| `Alcohol` | `float64` | Teor alcoÃ³lico |
| `Malicacid` | `float64` | Ãcido mÃ¡lico |
| `Ash` | `float64` | Cinzas |
| `Alcalinity_of_ash` | `float64` | Alcalinidade das cinzas |
| `Magnesium` | `int64` | MagnÃ©sio |
| `Total_phenols` | `float64` | FenÃ³is totais |
| `Flavanoids` | `float64` | Flavonoides |
| `Nonflavanoid_phenols` | `float64` | FenÃ³is nÃ£o flavonoides |
| `Proanthocyanins` | `float64` | Proantocianinas |
| `Color_intensity` | `float64` | Intensidade da cor |
| `Hue` | `float64` | Tonalidade |
| `0D280_0D315_of_diluted_wines` | `float64` | Medida de diluiÃ§Ã£o |
| `Proline` | `int64` | Prolina |

---

### ğŸ“Š Dataset 2: California Housing (RegressÃ£o)

**Fonte**: `sklearn.datasets`

#### ğŸ“‹ DescriÃ§Ã£o
Este dataset contÃ©m dados do censo de 1990 da CalifÃ³rnia. A tarefa Ã© prever o valor mediano das casas em um distrito com base em 8 variÃ¡veis demogrÃ¡ficas e geogrÃ¡ficas.

#### ğŸ“ˆ CaracterÃ­sticas dos Dados
- **Total de Registros**: 20.640 observaÃ§Ãµes
- **DimensÃµes**: 20.640 Ã— 8 variÃ¡veis de entrada (features)
- **Alvo**: Valor mediano das casas (variÃ¡vel contÃ­nua)

#### ğŸ”§ VariÃ¡veis do Dataset

| Categoria | VariÃ¡veis | DescriÃ§Ã£o |
|:---|:---|:---|
| **Renda** | `MedInc` | Renda mediana no distrito |
| **Idade** | `HouseAge` | Idade mediana das casas |
| **Estrutura** | `AveRooms` | MÃ©dia de cÃ´modos por domicÃ­lio |
| | `AveBedrms` | MÃ©dia de quartos por domicÃ­lio |
| **Demografia** | `Population` | PopulaÃ§Ã£o do distrito |
| | `AveOccup` | MÃ©dia de ocupantes por domicÃ­lio |
| **Geografia** | `Latitude` | Latitude do distrito |
| | `Longitude` | Longitude do distrito |

---

## ğŸ”§ Tecnologias Utilizadas

### ğŸ Linguagens e Frameworks
- **Python 3.8+**: Linguagem principal
- **Jupyter Notebook**: Ambiente de desenvolvimento
- **Google Colab**: Plataforma de execuÃ§Ã£o em nuvem

### ğŸ“Š Bibliotecas de AnÃ¡lise e ML
- **Pandas**: ManipulaÃ§Ã£o e anÃ¡lise de dados
- **NumPy**: ComputaÃ§Ã£o numÃ©rica
- **ucimlrepo**: Para carregar o dataset de vinhos
- **TensorFlow / Keras**: Para construÃ§Ã£o e treinamento das Redes Neurais (`Sequential`, `Dense`)
- **Scikit-learn**: Para prÃ©-processamento e modelos de Machine Learning clÃ¡ssicos
  - `StandardScaler`, `OneHotEncoder`, `train_test_split`
  - `RandomForestClassifier`, `RandomForestRegressor`
  - `accuracy_score`, `mean_absolute_error`, `mean_squared_error`

---

## ğŸ¤– Modelos de Machine Learning

### ğŸ“Š 1. Experimento de ClassificaÃ§Ã£o (Wine Dataset)

#### ğŸ¯ Objetivo
Classificar vinhos em uma de trÃªs categorias com base em suas caracterÃ­sticas quÃ­micas.

#### ğŸ§  Modelo de Rede Neural
- **Arquitetura**: `(13) -> Dense(32, relu) -> Dense(32, relu) -> Dense(3, softmax)`
- **Otimizador**: `Adam`
- **FunÃ§Ã£o de Perda**: `categorical_crossentropy`
- **Resultado (AcurÃ¡cia)**: `97.22%`

#### ğŸŒ³ Modelo de ComparaÃ§Ã£o (Random Forest Classifier)
- **HiperparÃ¢metros**: `n_estimators=100`, `random_state=42`
- **Resultado (AcurÃ¡cia)**: `100.00%`

#### ğŸ’¡ InterpretaÃ§Ã£o
No problema de classificaÃ§Ã£o de vinhos, o Random Forest atingiu a acurÃ¡cia perfeita de 100%, superando a rede neural. Isso sugere que, para este dataset pequeno e bem-estruturado, a capacidade do Random Forest de criar mÃºltiplas Ã¡rvores de decisÃ£o e combinar seus resultados foi extremamente eficaz.

### ğŸ“Š 2. Experimento de RegressÃ£o (California Housing Dataset)

#### ğŸ¯ Objetivo
Prever o valor mediano das casas na CalifÃ³rnia.

#### ğŸ§  Modelo de Rede Neural
- **Arquitetura**: `(8) -> Dense(64, relu) -> Dense(32, relu) -> Dense(16, relu) -> Dense(1, linear)`
- **Otimizador**: `Adam`
- **FunÃ§Ã£o de Perda**: `Mean Squared Error (mse)`
- **Resultados**:
  - **MAE**: `0.3556`
  - **RMSE**: `0.5299`

#### ğŸŒ³ Modelo de ComparaÃ§Ã£o (Random Forest Regressor)
- **HiperparÃ¢metros**: `n_estimators=100`, `random_state=42`
- **Resultados**:
  - **MAE**: `0.3274`
  - **RMSE**: `0.5051`

#### ğŸ’¡ InterpretaÃ§Ã£o
Assim como no caso anterior, o Random Forest Regressor apresentou um desempenho superior, com um erro (RMSE) menor em comparaÃ§Ã£o com a rede neural. O resultado indica que para dados tabulares como os deste problema, algoritmos de ensemble baseados em Ã¡rvores continuam sendo uma escolha muito forte e, muitas vezes, mais eficaz do que redes neurais mais complexas sem um ajuste fino extensivo.

---

## ğŸ’¡ Insights e ConclusÃµes

### ğŸ¯ Principais Descobertas

- **Superioridade do Random Forest em Dados Tabulares**: Para os dois datasets analisados, que sÃ£o exemplos clÃ¡ssicos de dados tabulares, o Random Forest (tanto para classificaÃ§Ã£o quanto para regressÃ£o) superou as Redes Neurais implementadas.
- **Simplicidade e EficÃ¡cia**: O Random Forest Ã© um modelo mais simples de treinar, exigindo menos prÃ©-processamento (nÃ£o precisa de codificaÃ§Ã£o *one-hot* para o alvo na classificaÃ§Ã£o) e menos ajuste de hiperparÃ¢metros para alcanÃ§ar um resultado de alta performance.
- **Potencial das Redes Neurais**: Embora superadas neste contexto, as Redes Neurais tÃªm um grande potencial. Seu desempenho poderia ser melhorado com mais dados, uma arquitetura mais complexa ou um ajuste fino de hiperparÃ¢metros (como taxa de aprendizado, nÃºmero de Ã©pocas, e estrutura das camadas).

### ğŸ“Š LimitaÃ§Ãµes
- **Datasets Pequenos**: Os datasets utilizados, especialmente o de vinhos, sÃ£o relativamente pequenos. Redes Neurais geralmente brilham com volumes de dados muito maiores.
- **Ajuste de HiperparÃ¢metros**: Os modelos de Redes Neurais foram construÃ­dos com arquiteturas padrÃ£o e nÃ£o passaram por um processo de otimizaÃ§Ã£o de hiperparÃ¢metros, o que poderia melhorar significativamente seus resultados.
- **AusÃªncia de VisualizaÃ§Ãµes**: O projeto foca puramente na comparaÃ§Ã£o de mÃ©tricas de desempenho, sem incluir anÃ¡lises exploratÃ³rias visuais que poderiam fornecer mais insights sobre os dados.

---

## ğŸ”® PrÃ³ximos Passos

- **OtimizaÃ§Ã£o de HiperparÃ¢metros**: Utilizar tÃ©cnicas como Grid Search ou Random Search para encontrar a melhor combinaÃ§Ã£o de hiperparÃ¢metros para as Redes Neurais.
- **AnÃ¡lise Visual dos Dados (EDA)**: Criar grÃ¡ficos e visualizaÃ§Ãµes para entender melhor a distribuiÃ§Ã£o e as correlaÃ§Ãµes presentes nos datasets.
- **Experimentar Outras Arquiteturas**: Testar diferentes arquiteturas de Redes Neurais, como adicionar mais camadas, usar diferentes funÃ§Ãµes de ativaÃ§Ã£o ou incluir camadas de regularizaÃ§Ã£o (Dropout).
- **Comparar com Outros Modelos**: Incluir outros algoritmos de machine learning na comparaÃ§Ã£o, como Gradient Boosting (XGBoost, LightGBM) e Support Vector Machines (SVM).

---

## ğŸ“š ReferÃªncias

### ğŸ”— Datasets
- **Wine Dataset**: [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/109/wine)
- **California Housing Dataset**: IncluÃ­do na biblioteca `sklearn.datasets`.

### ğŸ“š Bibliotecas e Ferramentas
- **Pandas**: [DocumentaÃ§Ã£o Oficial](https://pandas.pydata.org/docs/)
- **Scikit-learn**: [DocumentaÃ§Ã£o Oficial](https://scikit-learn.org/stable/)
- **TensorFlow/Keras**: [DocumentaÃ§Ã£o Oficial](https://www.tensorflow.org/guide)
- **UCIMLRepo**: [PyPI Project](https://pypi.org/project/ucimlrepo/)

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.
